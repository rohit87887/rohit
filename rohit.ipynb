{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e3a814f-61f7-46ff-9444-f77e377efed0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdated_health_insurance_dataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"updated_health_insurance_dataset.csv\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc63665-c40e-49d9-b465-7016f4c7333c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'rohit.ipynb', 'updated_health_insurance_dataset.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1bf799-5d59-449f-867d-860ae3b8edc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: xgboost in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy scikit-learn xgboost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7152ddd7",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"updated_health_insurance_dataset.csv\")\n",
    "\n",
    "# Encode categorical variables\n",
    "df = df.dropna()  # Drop missing values for simplicity\n",
    "le = LabelEncoder()\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Feature and target\n",
    "X = df.drop(\"Insurance_Type\", axis=1)\n",
    "y = df[\"Insurance_Type\"]\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define base models\n",
    "model1 = LogisticRegression(max_iter=1000)\n",
    "model2 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model3 = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "model4 = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Create voting classifier (hard voting)\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('lr', model1),\n",
    "    ('rf', model2),\n",
    "    ('gb', model3),\n",
    "    ('dt', model4)\n",
    "], voting='hard')\n",
    "\n",
    "# Train voting classifier\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "print(\"Voting Classifier Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5ae863-7190-472c-a65a-30d79acbf09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Classification Results (with Feature Selection):\n",
      "Decision Tree: Accuracy = 1.0000, F1 Score = 1.0000\n",
      "Random Forest: Accuracy = 1.0000, F1 Score = 1.0000\n",
      "AdaBoost: Accuracy = 0.8718, F1 Score = 0.8172\n",
      "XGBoost: Accuracy = 1.0000, F1 Score = 1.0000\n"
     ]
    }
   ],
   "source": [
    "# --------------------- CLASSIFICATION ---------------------\n",
    "X_cls = df.drop(columns=['Insurance Type', 'Annual Premium (USD)'])\n",
    "y_cls = df['Insurance Type']\n",
    "X_cls_train, X_cls_test, y_cls_train, y_cls_test = train_test_split(X_cls, y_cls, test_size=0.2, random_state=42)\n",
    "\n",
    "selector_cls = SelectFromModel(RandomForestClassifier(random_state=42)).fit(X_cls_train, y_cls_train)\n",
    "X_cls_train_fs = selector_cls.transform(X_cls_train)\n",
    "X_cls_test_fs = selector_cls.transform(X_cls_test)\n",
    "\n",
    "models_cls = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"XGBoost\": XGBClassifier()\n",
    "}\n",
    "\n",
    "print(\"ðŸ“Š Classification Results (with Feature Selection):\")\n",
    "for name, model in models_cls.items():\n",
    "    model.fit(X_cls_train_fs, y_cls_train)\n",
    "    preds = model.predict(X_cls_test_fs)\n",
    "    acc = accuracy_score(y_cls_test, preds)\n",
    "    f1 = f1_score(y_cls_test, preds, average='weighted')\n",
    "    print(f\"{name}: Accuracy = {acc:.4f}, F1 Score = {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84216dc-f676-46c8-90c8-8e1a55c82c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Ensemble: Accuracy = 1.0000, F1 Score = 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Stacked Ensemble for Classification\n",
    "stack_cls = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier()),\n",
    "        ('xgb', XGBClassifier()),\n",
    "        ('ada', AdaBoostClassifier())\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(),\n",
    "    passthrough=True\n",
    ")\n",
    "stack_cls.fit(X_cls_train_fs, y_cls_train)\n",
    "stack_preds = stack_cls.predict(X_cls_test_fs)\n",
    "acc = accuracy_score(y_cls_test, stack_preds)\n",
    "f1 = f1_score(y_cls_test, stack_preds, average='weighted')\n",
    "print(f\"Stacked Ensemble: Accuracy = {acc:.4f}, F1 Score = {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985a409b-83cd-48af-8ce3-bd466d8a48b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nðŸ“ˆ Regression Results (with Feature Selection):\n",
      "Decision Tree: MAE = 0.00, RMSE = 0.00, RÂ² = 1.0000\n",
      "Random Forest: MAE = 0.00, RMSE = 0.00, RÂ² = 1.0000\n",
      "AdaBoost: MAE = 0.11, RMSE = 0.13, RÂ² = 0.9837\n",
      "XGBoost: MAE = 0.00, RMSE = 0.00, RÂ² = 1.0000\n"
     ]
    }
   ],
   "source": [
    "# --------------------- REGRESSION ---------------------\n",
    "X_reg = df.drop(columns=['Annual Premium (USD)', 'Insurance Type'])\n",
    "y_reg = df['Annual Premium (USD)']\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "selector_reg = SelectFromModel(RandomForestRegressor(random_state=42)).fit(X_reg_train, y_reg_train)\n",
    "X_reg_train_fs = selector_reg.transform(X_reg_train)\n",
    "X_reg_test_fs = selector_reg.transform(X_reg_test)\n",
    "\n",
    "models_reg = {\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"AdaBoost\": AdaBoostRegressor(),\n",
    "    \"XGBoost\": XGBRegressor()\n",
    "}\n",
    "\n",
    "print(\"\\\\nðŸ“ˆ Regression Results (with Feature Selection):\")\n",
    "for name, model in models_reg.items():\n",
    "    model.fit(X_reg_train_fs, y_reg_train)\n",
    "    preds = model.predict(X_reg_test_fs)\n",
    "    mae = mean_absolute_error(y_reg_test, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y_reg_test, preds))\n",
    "    r2 = r2_score(y_reg_test, preds)\n",
    "    print(f\"{name}: MAE = {mae:.2f}, RMSE = {rmse:.2f}, RÂ² = {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c994f12-b49f-48a2-9b09-f49295ea28b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Ensemble: MAE = 0.00, RMSE = 0.00, RÂ² = 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Stacked Ensemble for Regression\n",
    "stack_reg = StackingRegressor(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestRegressor()),\n",
    "        ('xgb', XGBRegressor()),\n",
    "        ('ada', AdaBoostRegressor())\n",
    "    ],\n",
    "    final_estimator=LinearRegression(),\n",
    "    passthrough=True\n",
    ")\n",
    "stack_reg.fit(X_reg_train_fs, y_reg_train)\n",
    "stack_preds = stack_reg.predict(X_reg_test_fs)\n",
    "mae = mean_absolute_error(y_reg_test, stack_preds)\n",
    "rmse = np.sqrt(mean_squared_error(y_reg_test, stack_preds))\n",
    "r2 = r2_score(y_reg_test, stack_preds)\n",
    "print(f\"Stacked Ensemble: MAE = {mae:.2f}, RMSE = {rmse:.2f}, RÂ² = {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6579ab9a-2b27-4cb6-b91b-3ee03af7647a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset loaded successfully!\n",
      "  Person_ID  Age  Gender   BMI Smoker Pre-existing Condition  \\\n",
      "0   ID00001   74   Other  17.2     No                    NaN   \n",
      "1   ID00002   59  Female  23.2     No                    NaN   \n",
      "2   ID00003   64  Female  27.5     No                    NaN   \n",
      "3   ID00004   26    Male  17.4     No                    NaN   \n",
      "4   ID00005   25    Male  25.5    Yes                 Asthma   \n",
      "\n",
      "   Annual Premium (USD)         Insurance Type  Max Insurance Budget (USD)  \n",
      "0               5698.77   Standard Health Plan                    11811.38  \n",
      "1               9930.72   Standard Health Plan                    20582.60  \n",
      "2               8565.60   Standard Health Plan                    17753.23  \n",
      "3               5449.99   Standard Health Plan                    11295.75  \n",
      "4               8612.13  Respiratory Care Plan                    17849.67  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, RandomForestRegressor,\n",
    "    AdaBoostClassifier, AdaBoostRegressor,\n",
    "    StackingClassifier, StackingRegressor\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score,\n",
    "    mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "\n",
    "# Load and clean data\n",
    "try:\n",
    "    df = pd.read_csv(\"updated_health_insurance_dataset.csv\")\n",
    "    print(\" Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\" File not found. Please check if 'updated_health_insurance_dataset.csv' exists.\")\n",
    "\n",
    "# Check basic info\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92bb609-f5a9-42c1-ac81-d92a609dd918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Encoding and scaling completed!\n",
      "         Age  Gender       BMI  Smoker  Pre-existing Condition  \\\n",
      "4  -1.304691       1 -0.274792       1                       0   \n",
      "6  -0.855453       1  0.184718       0                       1   \n",
      "7   0.379952       0  1.730342       0                       3   \n",
      "9  -0.686989       0  0.282190       0                       1   \n",
      "10  1.446892       0 -0.010225       0                       1   \n",
      "\n",
      "    Annual Premium (USD)  Insurance Type  Max Insurance Budget (USD)  \n",
      "4               1.194354               3                    1.194355  \n",
      "6              -0.100464               2                   -0.100464  \n",
      "7              -0.462355               0                   -0.462355  \n",
      "9               0.513409               2                    0.513410  \n",
      "10             -0.270374               2                   -0.270375  \n"
     ]
    }
   ],
   "source": [
    "# Drop ID column if exists\n",
    "if 'Person_ID' in df.columns:\n",
    "    df.drop(columns=['Person_ID'], inplace=True)\n",
    "\n",
    "# Drop missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_cols = ['Gender', 'Smoker', 'Pre-existing Condition', 'Insurance Type']\n",
    "for col in label_cols:\n",
    "    if df[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "num_cols = ['Age', 'BMI', 'Annual Premium (USD)', 'Max Insurance Budget (USD)']\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "print(\"âœ… Encoding and scaling completed!\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "423424ee-581d-4c24-b64a-40623a5bc8ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder, StandardScaler\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_frame.py:988\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001b[39;00m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info\u001b[38;5;241m.\u001b[39mpydev_state \u001b[38;5;241m==\u001b[39m STATE_SUSPEND:\n\u001b[1;32m--> 988\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_wait_suspend(thread, frame, event, arg)\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_dispatch\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\_pydevd_bundle\\pydevd_frame.py:165\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_wait_suspend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdo_wait_suspend(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('updated_health_insurance_dataset.csv')  # or your local path\n",
    "\n",
    "# Drop missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Encode categorical features\n",
    "le = LabelEncoder()\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(\"Insurance Type\", axis=1)\n",
    "y = df[\"Insurance Type\"]\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define base models\n",
    "model1 = LogisticRegression(max_iter=1000)\n",
    "model2 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model3 = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "model4 = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Voting Classifier (Hard)\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('lr', model1),\n",
    "    ('rf', model2),\n",
    "    ('gb', model3),\n",
    "    ('dt', model4)\n",
    "], voting='hard')\n",
    "\n",
    "# Train and evaluate\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Output results\n",
    "print(\"Voting Classifier Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfefd93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy\n",
      "0  Logistic Regression       1.0\n",
      "1        Random Forest       1.0\n",
      "2    Gradient Boosting       1.0\n",
      "3        Decision Tree       1.0\n",
      "4    Voting Classifier       1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('updated_health_insurance_dataset.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "# Label encode categorical columns\n",
    "le = LabelEncoder()\n",
    "for col in df.select_dtypes(include='object'):\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(\"Insurance Type\", axis=1)\n",
    "y = df[\"Insurance Type\"]\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define individual models\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit individual models\n",
    "lr.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "gb.fit(X_train, y_train)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Voting Classifier\n",
    "voting = VotingClassifier(estimators=[\n",
    "    ('lr', lr), ('rf', rf), ('gb', gb), ('dt', dt)\n",
    "], voting='hard')\n",
    "\n",
    "voting.fit(X_train, y_train)\n",
    "\n",
    "# Get accuracy scores\n",
    "results = {\n",
    "    \"Model\": [\"Logistic Regression\", \"Random Forest\", \"Gradient Boosting\", \"Decision Tree\", \"Voting Classifier\"],\n",
    "    \"Accuracy\": [\n",
    "        accuracy_score(y_test, lr.predict(X_test)),\n",
    "        accuracy_score(y_test, rf.predict(X_test)),\n",
    "        accuracy_score(y_test, gb.predict(X_test)),\n",
    "        accuracy_score(y_test, dt.predict(X_test)),\n",
    "        accuracy_score(y_test, voting.predict(X_test))\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create comparison table\n",
    "comparison_df = pd.DataFrame(results)\n",
    "print(comparison_df.sort_values(by='Accuracy', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69cf9097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy  MSE  R2 Score  Rank     Evaluation\n",
      "0  Logistic Regression       1.0  0.0       1.0     3  Good Accuracy\n",
      "1        Random Forest       1.0  0.0       1.0     3  Good Accuracy\n",
      "2    Gradient Boosting       1.0  0.0       1.0     3  Good Accuracy\n",
      "3        Decision Tree       1.0  0.0       1.0     3  Good Accuracy\n",
      "4    Voting Classifier       1.0  0.0       1.0     3  Good Accuracy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('updated_health_insurance_dataset.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "# Encode categorical columns\n",
    "le = LabelEncoder()\n",
    "for col in df.select_dtypes(include='object'):\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Feature and target\n",
    "X = df.drop(\"Insurance Type\", axis=1)\n",
    "y = df[\"Insurance Type\"]\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Train models and store results\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_test, y_pred),\n",
    "        \"R2 Score\": r2_score(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "# Add Voting Classifier\n",
    "voting = VotingClassifier(estimators=[(k, v) for k, v in models.items()], voting='hard')\n",
    "voting.fit(X_train, y_train)\n",
    "voting_pred = voting.predict(X_test)\n",
    "results.append({\n",
    "    \"Model\": \"Voting Classifier\",\n",
    "    \"Accuracy\": accuracy_score(y_test, voting_pred),\n",
    "    \"MSE\": mean_squared_error(y_test, voting_pred),\n",
    "    \"R2 Score\": r2_score(y_test, voting_pred)\n",
    "})\n",
    "\n",
    "# Convert to DataFrame\n",
    "comparison_df = pd.DataFrame(results)\n",
    "\n",
    "# Add rankings and evaluation\n",
    "comparison_df['Rank'] = comparison_df['Accuracy'].rank(ascending=False).astype(int)\n",
    "comparison_df['Evaluation'] = comparison_df['Accuracy'].apply(lambda x: \"Good Accuracy\" if x > 0.85 else \"Less Accuracy\")\n",
    "\n",
    "# Sort by accuracy\n",
    "comparison_df = comparison_df.sort_values(by='Accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba11ef92",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DecisionTreeClassifier' from 'sklearn.ensemble' (c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder, StandardScaler\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      6\u001b[0m     RandomForestClassifier, GradientBoostingClassifier,\n\u001b[0;32m      7\u001b[0m     DecisionTreeClassifier, VotingClassifier, AdaBoostClassifier\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, mean_squared_error, r2_score\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'DecisionTreeClassifier' from 'sklearn.ensemble' (c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier,\n",
    "    DecisionTreeClassifier, VotingClassifier, AdaBoostClassifier\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('updated_health_insurance_dataset.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "# Encode categorical columns\n",
    "le = LabelEncoder()\n",
    "for col in df.select_dtypes(include='object'):\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Feature and target\n",
    "X = df.drop(\"Insurance Type\", axis=1)\n",
    "y = df[\"Insurance Type\"]\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_test, y_pred),\n",
    "        \"R2 Score\": r2_score(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "# Add Voting Classifier\n",
    "voting = VotingClassifier(estimators=[(k, v) for k, v in models.items()], voting='hard')\n",
    "voting.fit(X_train, y_train)\n",
    "voting_pred = voting.predict(X_test)\n",
    "results.append({\n",
    "    \"Model\": \"Voting Classifier\",\n",
    "    \"Accuracy\": accuracy_score(y_test, voting_pred),\n",
    "    \"MSE\": mean_squared_error(y_test, voting_pred),\n",
    "    \"R2 Score\": r2_score(y_test, voting_pred)\n",
    "})\n",
    "\n",
    "# Format results into DataFrame\n",
    "comparison_df = pd.DataFrame(results)\n",
    "comparison_df['Rank'] = comparison_df['Accuracy'].rank(ascending=False).astype(int)\n",
    "comparison_df['Evaluation'] = comparison_df['Accuracy'].apply(lambda x: \"Good Accuracy\" if x > 0.85 else \"Less Accuracy\")\n",
    "comparison_df = comparison_df.sort_values(by='Accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90ceca9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy       MSE  R2 Score  Rank     Evaluation\n",
      "0  Logistic Regression  1.000000  0.000000  1.000000     3  Good Accuracy\n",
      "1        Random Forest  1.000000  0.000000  1.000000     3  Good Accuracy\n",
      "2    Gradient Boosting  1.000000  0.000000  1.000000     3  Good Accuracy\n",
      "3        Decision Tree  1.000000  0.000000  1.000000     3  Good Accuracy\n",
      "4              XGBoost  1.000000  0.000000  1.000000     3  Good Accuracy\n",
      "5    Voting Classifier  1.000000  0.000000  1.000000     3  Good Accuracy\n",
      "6             AdaBoost  0.871779  0.128221  0.893681     7  Good Accuracy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier,\n",
    "    AdaBoostClassifier, VotingClassifier\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('updated_health_insurance_dataset.csv')  # adjust path if needed\n",
    "df = df.dropna()\n",
    "\n",
    "# Encode categorical features\n",
    "le = LabelEncoder()\n",
    "for col in df.select_dtypes(include='object'):\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(\"Insurance Type\", axis=1)\n",
    "y = df[\"Insurance Type\"]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_test, y_pred),\n",
    "        \"R2 Score\": r2_score(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "# Voting Classifier using all models\n",
    "voting = VotingClassifier(estimators=[(k, v) for k, v in models.items()], voting='hard')\n",
    "voting.fit(X_train, y_train)\n",
    "voting_pred = voting.predict(X_test)\n",
    "results.append({\n",
    "    \"Model\": \"Voting Classifier\",\n",
    "    \"Accuracy\": accuracy_score(y_test, voting_pred),\n",
    "    \"MSE\": mean_squared_error(y_test, voting_pred),\n",
    "    \"R2 Score\": r2_score(y_test, voting_pred)\n",
    "})\n",
    "\n",
    "# Create DataFrame from results\n",
    "comparison_df = pd.DataFrame(results)\n",
    "\n",
    "# Add ranking and evaluation label\n",
    "comparison_df['Rank'] = comparison_df['Accuracy'].rank(ascending=False).astype(int)\n",
    "comparison_df['Evaluation'] = comparison_df['Accuracy'].apply(lambda x: \"Good Accuracy\" if x > 0.85 else \"Less Accuracy\")\n",
    "comparison_df = comparison_df.sort_values(by='Accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display final result\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "082e7a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Model  Accuracy       MSE  R2 Score     Evaluation  Rank\n",
      "0        XGBoost  1.000000  0.000000  1.000000  Good Accuracy     2\n",
      "1  Random Forest  1.000000  0.000000  1.000000  Less Accuracy     2\n",
      "2  Decision Tree  1.000000  0.000000  1.000000  Less Accuracy     2\n",
      "3       AdaBoost  0.871779  0.128221  0.893681  Good Accuracy     4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('updated_health_insurance_dataset.csv')  # Adjust path if needed\n",
    "df = df.dropna()\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "for col in df.select_dtypes(include='object'):\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(\"Insurance Type\", axis=1)\n",
    "y = df[\"Insurance Type\"]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Train, predict, and collect results\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Custom evaluation rule\n",
    "    if name in ['XGBoost', 'AdaBoost']:\n",
    "        evaluation = 'Good Accuracy'\n",
    "    else:\n",
    "        evaluation = 'Less Accuracy'\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"MSE\": mse,\n",
    "        \"R2 Score\": r2,\n",
    "        \"Evaluation\": evaluation\n",
    "    })\n",
    "\n",
    "# Sort with XGBoost at the top\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results.sort_values(by=\"Accuracy\", ascending=False).reset_index(drop=True)\n",
    "df_results[\"Rank\"] = df_results[\"Accuracy\"].rank(ascending=False).astype(int)\n",
    "\n",
    "# Output table\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed01550a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Model  Accuracy       MSE  R2 Score     Evaluation  Rank\n",
      "0        XGBoost  1.000000  0.000000  1.000000  Good Accuracy     1\n",
      "1       AdaBoost  0.871779  0.128221  0.893681  Good Accuracy     2\n",
      "2  Decision Tree  1.000000  0.000000  1.000000  Less Accuracy     3\n",
      "3  Random Forest  1.000000  0.000000  1.000000  Less Accuracy     4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('updated_health_insurance_dataset.csv')  # Change path if needed\n",
    "df = df.dropna()\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "for col in df.select_dtypes(include='object'):\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(\"Insurance Type\", axis=1)\n",
    "y = df[\"Insurance Type\"]\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define and train models\n",
    "models = {\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    evaluation = \"Good Accuracy\" if name in [\"XGBoost\", \"AdaBoost\"] else \"Less Accuracy\"\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"MSE\": mse,\n",
    "        \"R2 Score\": r2,\n",
    "        \"Evaluation\": evaluation\n",
    "    })\n",
    "\n",
    "# Manually assign rank based on your instruction\n",
    "ranking_order = [\"XGBoost\", \"AdaBoost\", \"Decision Tree\", \"Random Forest\"]\n",
    "results_sorted = sorted(results, key=lambda x: ranking_order.index(x[\"Model\"]))\n",
    "for i, row in enumerate(results_sorted):\n",
    "    row[\"Rank\"] = i + 1\n",
    "\n",
    "# Final DataFrame\n",
    "final_df = pd.DataFrame(results_sorted)\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65830f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Model  Accuracy       MSE  R2 Score     Evaluation\n",
      "0        XGBoost  1.000000  0.000000  1.000000  Good Accuracy\n",
      "1       AdaBoost  0.871779  0.128221  0.893681  Good Accuracy\n",
      "2  Decision Tree  1.000000  0.000000  1.000000  Less Accuracy\n",
      "3  Random Forest  1.000000  0.000000  1.000000  Less Accuracy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('updated_health_insurance_dataset.csv')  # Adjust path if needed\n",
    "df = df.dropna()\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "for col in df.select_dtypes(include='object'):\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Feature and target\n",
    "X = df.drop(\"Insurance Type\", axis=1)\n",
    "y = df[\"Insurance Type\"]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    evaluation = \"Good Accuracy\" if name in [\"XGBoost\", \"AdaBoost\"] else \"Less Accuracy\"\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"MSE\": mse,\n",
    "        \"R2 Score\": r2,\n",
    "        \"Evaluation\": evaluation\n",
    "    })\n",
    "\n",
    "# Create DataFrame (no ranking)\n",
    "final_df = pd.DataFrame(results)\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0608aa4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder, MinMaxScaler\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Load and preprocess dataset\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Load and preprocess dataset\n",
    "df = pd.read_csv(\"updated_health_insurance_dataset.csv\")\n",
    "df = df.dropna()\n",
    "\n",
    "# Encode categorical columns\n",
    "le = LabelEncoder()\n",
    "for col in df.select_dtypes(include='object'):\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Sort by Person_ID (simulating a time sequence)\n",
    "df = df.sort_values(by=\"Person_ID\")\n",
    "\n",
    "# Scale features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df.drop([\"Annual Premium (USD)\"], axis=1))\n",
    "target = df[\"Annual Premium (USD)\"].values\n",
    "\n",
    "# Create sequences\n",
    "X = []\n",
    "y = []\n",
    "sequence_length = 10\n",
    "\n",
    "for i in range(sequence_length, len(scaled_data)):\n",
    "    X.append(scaled_data[i-sequence_length:i])\n",
    "    y.append(target[i])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Train/test split\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# Define LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Plot actual vs predicted\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test[:100], label='Actual')\n",
    "plt.plot(y_pred[:100], label='Predicted')\n",
    "plt.title(\"LSTM Prediction vs Actual (Annual Premium)\")\n",
    "plt.xlabel(\"Sample\")\n",
    "plt.ylabel(\"Premium (USD)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61db2022",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder, MinMaxScaler\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Load and preprocess dataset\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Load and preprocess dataset\n",
    "df = pd.read_csv(\"updated_health_insurance_dataset.csv\")\n",
    "df = df.dropna()\n",
    "\n",
    "# Encode categorical columns\n",
    "le = LabelEncoder()\n",
    "for col in df.select_dtypes(include='object'):\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Sort by Person_ID (simulating a time sequence)\n",
    "df = df.sort_values(by=\"Person_ID\")\n",
    "\n",
    "# Scale features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df.drop([\"Annual Premium (USD)\"], axis=1))\n",
    "target = df[\"Annual Premium (USD)\"].values\n",
    "\n",
    "# Create sequences\n",
    "X = []\n",
    "y = []\n",
    "sequence_length = 10\n",
    "\n",
    "for i in range(sequence_length, len(scaled_data)):\n",
    "    X.append(scaled_data[i-sequence_length:i])\n",
    "    y.append(target[i])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Train/test split\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# Define LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Plot actual vs predicted\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test[:100], label='Actual')\n",
    "plt.plot(y_pred[:100], label='Predicted')\n",
    "plt.title(\"LSTM Prediction vs Actual (Annual Premium)\")\n",
    "plt.xlabel(\"Sample\")\n",
    "plt.ylabel(\"Premium (USD)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
